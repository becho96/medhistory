#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
–∏ —Å–æ–∑–¥–∞–Ω–∏—è –º–∞–ø–ø–∏–Ω–≥–∞ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.
"""

import asyncio
import sys
import os
from pathlib import Path
from collections import defaultdict, Counter
import json
import re

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "backend"))

from motor.motor_asyncio import AsyncIOMotorClient
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
env_file = project_root / ".env.local"
if not env_file.exists():
    env_file = project_root / "environments" / "local.env"
load_dotenv(env_file)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è MongoDB
MONGO_USER = os.getenv("MONGO_INITDB_ROOT_USERNAME", "admin")
MONGO_PASSWORD = os.getenv("MONGO_PASSWORD", "mongodb_local_pass")
MONGO_DB = os.getenv("MONGO_INITDB_DATABASE", "medhistory")

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ö–æ—Å—Ç
MONGODB_URL_ENV = os.getenv("MONGODB_URL")
if MONGODB_URL_ENV:
    MONGODB_URL = MONGODB_URL_ENV
else:
    is_docker = os.path.exists("/.dockerenv") or os.getenv("DOCKER_CONTAINER") == "true"
    MONGO_HOST = "mongodb" if is_docker else os.getenv("MONGODB_HOST", "localhost")
    MONGO_PORT = os.getenv("MONGODB_PORT", "27017")
    MONGODB_URL = f"mongodb://{MONGO_USER}:{MONGO_PASSWORD}@{MONGO_HOST}:{MONGO_PORT}/{MONGO_DB}?authSource=admin"


async def analyze_all_units():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    
    print(f"üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB...")
    client = AsyncIOMotorClient(MONGODB_URL)
    db = client[MONGO_DB]
    collection = db.document_metadata
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
    print("\nüìä –°–±–æ—Ä –≤—Å–µ—Ö –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è...")
    pipeline = [
        {"$match": {"extracted_data.lab_results": {"$exists": True, "$ne": []}}},
        {"$project": {"extracted_data.lab_results": 1}},
        {"$unwind": "$extracted_data.lab_results"},
        {
            "$group": {
                "_id": "$extracted_data.lab_results.unit",
                "count": {"$sum": 1},
                "test_names": {"$addToSet": "$extracted_data.lab_results.test_name"}
            }
        },
        {"$sort": {"count": -1}}
    ]
    
    units_data = []
    async for doc in collection.aggregate(pipeline):
        unit = doc["_id"]
        count = doc.get("count", 0)
        test_names = doc.get("test_names", [])
        units_data.append({
            "unit": unit,
            "count": count,
            "test_names": sorted(test_names)[:10]  # –ü–µ—Ä–≤—ã–µ 10 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        })
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(units_data)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è\n")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ –µ–¥–∏–Ω–∏—Ü—ã
    print("üîç –ê–Ω–∞–ª–∏–∑ –ø–æ—Ö–æ–∂–∏—Ö –µ–¥–∏–Ω–∏—Ü...\n")
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É, —É–±–∏—Ä–∞–µ–º —Ç–æ—á–∫–∏)
    def normalize_for_comparison(unit):
        if not unit:
            return None
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ, –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        normalized = str(unit).strip().lower()
        normalized = re.sub(r'\.+$', '', normalized)  # –£–±–∏—Ä–∞–µ–º —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ
        normalized = re.sub(r'\s+', ' ', normalized)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
        return normalized
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é
    normalized_groups = defaultdict(list)
    for unit_data in units_data:
        unit = unit_data["unit"]
        normalized = normalize_for_comparison(unit)
        normalized_groups[normalized].append(unit_data)
    
    # –ù–∞—Ö–æ–¥–∏–º –≥—Ä—É–ø–ø—ã —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏
    duplicates = {k: v for k, v in normalized_groups.items() if len(v) > 1 and k is not None}
    
    print(f"üìå –ù–∞–π–¥–µ–Ω–æ {len(duplicates)} –≥—Ä—É–ø–ø —Å –¥—É–±–ª–∏—Ä—É—é—â–∏–º–∏—Å—è –µ–¥–∏–Ω–∏—Ü–∞–º–∏:\n")
    
    for normalized, variants in sorted(duplicates.items(), key=lambda x: sum(v["count"] for v in x[1]), reverse=True):
        total_count = sum(v["count"] for v in variants)
        print(f"  –ì—Ä—É–ø–ø–∞: '{normalized}' (–≤—Å–µ–≥–æ {total_count} –∑–∞–ø–∏—Å–µ–π)")
        for variant in sorted(variants, key=lambda x: x["count"], reverse=True):
            print(f"    - '{variant['unit']}' ({variant['count']} –∑–∞–ø–∏—Å–µ–π)")
        print()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –µ–¥–∏–Ω–∏—Ü
    output_file = Path("/app/scripts/all_units_analysis.json") if os.path.exists("/.dockerenv") else project_root / "backend" / "scripts" / "all_units_analysis.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "total_unique_units": len(units_data),
            "duplicate_groups": {
                k: [{"unit": v["unit"], "count": v["count"]} for v in variants]
                for k, variants in duplicates.items()
            },
            "all_units": units_data
        }, f, ensure_ascii=False, indent=2)
    
    print(f"üíæ –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü: {len(units_data)}")
    print(f"   –ì—Ä—É–ø–ø —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏: {len(duplicates)}")
    print(f"   –ï–¥–∏–Ω–∏—Ü —Å null: {sum(1 for u in units_data if u['unit'] is None)}")
    
    client.close()
    return units_data, duplicates


if __name__ == "__main__":
    asyncio.run(analyze_all_units())

