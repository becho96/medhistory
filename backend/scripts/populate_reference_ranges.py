#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã analyte_standards —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
–∏–∑ CSV —Ñ–∞–π–ª–∞ test_unit_reference_ranges.csv
"""

import csv
import re
import os
from decimal import Decimal
from typing import Optional, Tuple

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker


def parse_reference_range(range_str: str) -> Optional[Tuple[Optional[float], Optional[float]]]:
    """
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º.
    
    Returns:
        (min_value, max_value) –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
    """
    if not range_str or range_str == "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö":
        return None
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    range_str = range_str.strip()
    
    # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏ –¥–ª—è —á–∏—Å–µ–ª
    range_str = range_str.replace(',', '.')
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞: "X-Y" –∏–ª–∏ "X - Y"
    range_pattern = r'(\d+(?:\.\d+)?)\s*[-‚Äì‚Äî]\s*(\d+(?:\.\d+)?)'
    match = re.search(range_pattern, range_str)
    if match:
        return (float(match.group(1)), float(match.group(2)))
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è "< X" –∏–ª–∏ "<X"
    max_pattern = r'<?[<]\s*(\d+(?:\.\d+)?)'
    match = re.search(max_pattern, range_str)
    if match:
        return (None, float(match.group(1)))
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è "> X" –∏–ª–∏ ">X"
    min_pattern = r'>?\s*>\s*(\d+(?:\.\d+)?)'
    match = re.search(min_pattern, range_str)
    if match:
        return (float(match.group(1)), None)
    
    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —á–∏—Å–ª–æ - —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
    single_num = r'^(\d+(?:\.\d+)?)$'
    match = re.match(single_num, range_str)
    if match:
        return (None, float(match.group(1)))
    
    return None


def extract_test_name_and_unit(combined: str) -> Tuple[str, Optional[str]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞ –∏ –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "–ù–∞–∑–≤–∞–Ω–∏–µ (–µ–¥–∏–Ω–∏—Ü–∞)"
    
    Returns:
        (test_name, unit)
    """
    # –ü–∞—Ç—Ç–µ—Ä–Ω: "–ù–∞–∑–≤–∞–Ω–∏–µ (–µ–¥–∏–Ω–∏—Ü–∞)"
    pattern = r'^(.+?)\s*\((.+?)\)$'
    match = re.match(pattern, combined)
    
    if match:
        test_name = match.group(1).strip()
        unit = match.group(2).strip()
        return (test_name, unit)
    
    # –ï—Å–ª–∏ –Ω–µ—Ç —Å–∫–æ–±–æ–∫, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ
    return (combined.strip(), None)


def normalize_unit(unit: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    if not unit:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    unit = unit.strip()
    
    # –ó–∞–º–µ–Ω—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–ø–∏—Å–∏ —Å—Ç–µ–ø–µ–Ω–µ–π
    unit = unit.replace('10*9', '√ó10‚Åπ')
    unit = unit.replace('10^9', '√ó10‚Åπ')
    unit = unit.replace('10*12', '√ó10¬π¬≤')
    unit = unit.replace('10^12', '√ó10¬π¬≤')
    unit = unit.replace('x10*12', '√ó10¬π¬≤')
    
    return unit.lower()


def load_csv_data(csv_file: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV —Ñ–∞–π–ª–∞"""
    data = []
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            combined = row['–ê–Ω–∞–ª–∏–∑ (–µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è)']
            ranges_str = row['–î–∏–∞–ø–∞–∑–æ–Ω—ã –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π']
            
            test_name, unit = extract_test_name_and_unit(combined)
            
            # –ü–∞—Ä—Å–∏–º –≤—Å–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã (–º–æ–≥—É—Ç –±—ã—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ ";")
            ranges = []
            if ranges_str and ranges_str != "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö":
                for single_range in ranges_str.split(';'):
                    parsed = parse_reference_range(single_range.strip())
                    if parsed:
                        ranges.append(parsed)
            
            if ranges:
                data.append({
                    'test_name': test_name,
                    'unit': unit,
                    'ranges': ranges
                })
    
    return data


def find_analyte_id(conn, test_name: str, unit: Optional[str]):
    """
    –ò—â–µ—Ç ID –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ analyte_standards –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏ –µ–¥–∏–Ω–∏—Ü–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è
    """
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ canonical_name
    result = conn.execute(
        text("""
            SELECT id, canonical_name, standard_unit 
            FROM analyte_standards 
            WHERE canonical_name = :name
        """),
        {"name": test_name}
    )
    
    row = result.fetchone()
    if row:
        analyte_id, canonical_name, standard_unit = row
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü (–µ—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ —É–∫–∞–∑–∞–Ω–∞)
        if unit:
            if normalize_unit(standard_unit) == normalize_unit(unit):
                return analyte_id, canonical_name, standard_unit
        else:
            # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –≤ CSV, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            return analyte_id, canonical_name, standard_unit
    
    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ —Å–∏–Ω–æ–Ω–∏–º—ã
    result = conn.execute(
        text("""
            SELECT a.id, a.canonical_name, a.standard_unit
            FROM analyte_standards a
            JOIN analyte_synonyms s ON a.id = s.analyte_id
            WHERE s.synonym = :name OR s.synonym_lower = :name_lower
        """),
        {"name": test_name, "name_lower": test_name.lower()}
    )
    
    row = result.fetchone()
    if row:
        analyte_id, canonical_name, standard_unit = row
        
        if unit:
            if normalize_unit(standard_unit) == normalize_unit(unit):
                return analyte_id, canonical_name, standard_unit
        else:
            return analyte_id, canonical_name, standard_unit
    
    return None, None, None


def update_reference_ranges(database_url: str, csv_file: str, dry_run: bool = False):
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü–µ analyte_standards
    """
    engine = create_engine(database_url)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV...")
    csv_data = load_csv_data(csv_file)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(csv_data)} –∑–∞–ø–∏—Å–µ–π")
    print()
    
    updated_count = 0
    not_found_count = 0
    skipped_count = 0
    
    with engine.connect() as conn:
        for item in csv_data:
            test_name = item['test_name']
            unit = item['unit']
            ranges = item['ranges']
            
            # –ò—â–µ–º –∞–Ω–∞–ª–∏–∑ –≤ –ë–î
            analyte_id, canonical_name, standard_unit = find_analyte_id(conn, test_name, unit)
            
            if not analyte_id:
                print(f"‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω: {test_name} ({unit})")
                not_found_count += 1
                continue
            
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (–æ–±—ã—á–Ω–æ —Å–∞–º—ã–π —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–π)
            min_val, max_val = ranges[0]
            
            # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∏–ª–∏ —Å–∞–º—ã–π —à–∏—Ä–æ–∫–∏–π
            if len(ranges) > 1:
                all_mins = [r[0] for r in ranges if r[0] is not None]
                all_maxs = [r[1] for r in ranges if r[1] is not None]
                
                if all_mins:
                    min_val = min(all_mins)  # –ë–µ—Ä–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏–∑ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö
                if all_maxs:
                    max_val = max(all_maxs)  # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏–∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Decimal –¥–ª—è PostgreSQL
            min_decimal = Decimal(str(min_val)) if min_val is not None else None
            max_decimal = Decimal(str(max_val)) if max_val is not None else None
            
            if dry_run:
                print(f"üîç {canonical_name} ({standard_unit}): {min_val} - {max_val}")
            else:
                # –û–±–Ω–æ–≤–ª—è–µ–º –ë–î (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ–±–æ–∏—Ö –ø–æ–ª–æ–≤)
                update_sql = text("""
                    UPDATE analyte_standards 
                    SET 
                        reference_male_min = :min_val,
                        reference_male_max = :max_val,
                        reference_female_min = :min_val,
                        reference_female_max = :max_val,
                        updated_at = NOW()
                    WHERE id = :analyte_id
                """)
                
                conn.execute(update_sql, {
                    "min_val": min_decimal,
                    "max_val": max_decimal,
                    "analyte_id": analyte_id
                })
                
                conn.commit()
                
                print(f"‚úÖ {canonical_name} ({standard_unit}): {min_val} - {max_val}")
                updated_count += 1
    
    print()
    print("=" * 80)
    if dry_run:
        print("üîç –¢–ï–°–¢–û–í–´–ô –†–ï–ñ–ò–ú - –∏–∑–º–µ–Ω–µ–Ω–∏—è –ù–ï –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")
    print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_count}")
    print(f"‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {not_found_count}")
    print("=" * 80)
    
    engine.dispose()


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ analyte_standards'
    )
    parser.add_argument(
        '--database-url',
        default='postgresql://medhistory_user:medhistory_pass@localhost:5432/medhistory',
        help='URL –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostgreSQL'
    )
    parser.add_argument(
        '--csv-file',
        default='test_unit_reference_ranges.csv',
        help='–ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='–¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (–Ω–µ –ø—Ä–∏–º–µ–Ω—è—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è)'
    )
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ CSV —Ñ–∞–π–ª–∞
    script_dir = os.path.dirname(__file__)
    csv_path = os.path.join(script_dir, args.csv_file)
    
    if not os.path.exists(csv_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
        return
    
    print("=" * 80)
    print("üì• –ó–ê–ü–û–õ–ù–ï–ù–ò–ï –†–ï–§–ï–†–ï–ù–°–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô")
    print("=" * 80)
    print(f"CSV —Ñ–∞–π–ª: {csv_path}")
    print(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {args.database_url}")
    if args.dry_run:
        print("‚ö†Ô∏è  –¢–ï–°–¢–û–í–´–ô –†–ï–ñ–ò–ú (–∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã)")
    print()
    
    try:
        update_reference_ranges(args.database_url, csv_path, args.dry_run)
        print()
        print("‚úÖ –ì–æ—Ç–æ–≤–æ!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
